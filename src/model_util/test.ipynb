{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'age': tensor([[0.4721, 0.5465, 0.5687, 0.2547],\n",
      "        [0.3115, 0.2972, 0.4721, 0.6852]]), 'backpack': tensor([[0.2100],\n",
      "        [0.5432]]), 'bag': tensor([[0.0451],\n",
      "        [0.6082]]), 'clothes': tensor([[0.7421],\n",
      "        [0.6868]]), 'down': tensor([[0.1820],\n",
      "        [0.9185]]), 'down_colours': tensor([[0.0842, 0.6634, 0.6893, 0.0692, 0.1263, 0.3042, 0.3638, 0.8986, 0.3382],\n",
      "        [0.5533, 0.6044, 0.7600, 0.7034, 0.8818, 0.3170, 0.1555, 0.7475, 0.2622]]), 'gender': tensor([[0.1863],\n",
      "        [0.5716]]), 'hair': tensor([[0.2857],\n",
      "        [0.5859]]), 'handbag': tensor([[0.2884],\n",
      "        [0.6621]]), 'hat': tensor([[0.4549],\n",
      "        [0.3198]]), 'up': tensor([[0.7707],\n",
      "        [0.5234]]), 'up_colours': tensor([[0.8655, 0.5658, 0.2959, 0.5635, 0.4558, 0.9680, 0.5970, 0.3177],\n",
      "        [0.7135, 0.0204, 0.8029, 0.9953, 0.3617, 0.3462, 0.7350, 0.6144]])}\n",
      "[{'age': tensor([2]), 'backpack': tensor([0]), 'bag': tensor([1]), 'clothes': tensor([1]), 'down': tensor([0]), 'down_colours': tensor([4]), 'gender': tensor([0]), 'hair': tensor([1]), 'handbag': tensor([1]), 'hat': tensor([0]), 'up': tensor([1]), 'up_colours': tensor([3])}, {'age': tensor([2]), 'backpack': tensor([0]), 'bag': tensor([1]), 'clothes': tensor([1]), 'down': tensor([0]), 'down_colours': tensor([4]), 'gender': tensor([0]), 'hair': tensor([1]), 'handbag': tensor([1]), 'hat': tensor([0]), 'up': tensor([1]), 'up_colours': tensor([3])}]\n",
      "{'age': tensor([[0.4721, 0.5465, 0.5687, 0.2547],\n",
      "        [0.3115, 0.2972, 0.4721, 0.6852]]), 'backpack': tensor([[0.],\n",
      "        [1.]]), 'bag': tensor([[0.],\n",
      "        [1.]]), 'clothes': tensor([[1.],\n",
      "        [1.]]), 'down': tensor([[0.],\n",
      "        [1.]]), 'down_colours': tensor([[0.0842, 0.6634, 0.6893, 0.0692, 0.1263, 0.3042, 0.3638, 0.8986, 0.3382],\n",
      "        [0.5533, 0.6044, 0.7600, 0.7034, 0.8818, 0.3170, 0.1555, 0.7475, 0.2622]]), 'gender': tensor([[0.],\n",
      "        [1.]]), 'hair': tensor([[0.],\n",
      "        [1.]]), 'handbag': tensor([[0.],\n",
      "        [1.]]), 'hat': tensor([[0.],\n",
      "        [0.]]), 'up': tensor([[1.],\n",
      "        [1.]]), 'up_colours': tensor([[0.8655, 0.5658, 0.2959, 0.5635, 0.4558, 0.9680, 0.5970, 0.3177],\n",
      "        [0.7135, 0.0204, 0.8029, 0.9953, 0.3617, 0.3462, 0.7350, 0.6144]])}\n",
      "[[2], [2]]\n",
      "[2, 3]\n",
      "[[4], [4]]\n",
      "[7, 4]\n",
      "[[3], [3]]\n",
      "[5, 3]\n",
      "{'age': {'recall': array([0.5, 0. ]), 'precision': array([1., 0.]), 'fscore': array([0.66666667, 0.        ]), 'accuracy': 0.5}, 'backpack': {'recall': array([0.5, 0. ]), 'precision': array([1., 0.]), 'fscore': array([0.66666667, 0.        ]), 'accuracy': 0.5}, 'bag': {'recall': array([0. , 0.5]), 'precision': array([0., 1.]), 'fscore': array([0.        , 0.66666667]), 'accuracy': 0.5}, 'clothes': {'recall': array([1.]), 'precision': array([1.]), 'fscore': array([1.]), 'accuracy': 1.0}, 'down': {'recall': array([0.5, 0. ]), 'precision': array([1., 0.]), 'fscore': array([0.66666667, 0.        ]), 'accuracy': 0.5}, 'down_colours': {'recall': array([0.5, 0. ]), 'precision': array([1., 0.]), 'fscore': array([0.66666667, 0.        ]), 'accuracy': 0.5}, 'gender': {'recall': array([0.5, 0. ]), 'precision': array([1., 0.]), 'fscore': array([0.66666667, 0.        ]), 'accuracy': 0.5}, 'hair': {'recall': array([0. , 0.5]), 'precision': array([0., 1.]), 'fscore': array([0.        , 0.66666667]), 'accuracy': 0.5}, 'handbag': {'recall': array([0. , 0.5]), 'precision': array([0., 1.]), 'fscore': array([0.        , 0.66666667]), 'accuracy': 0.5}, 'hat': {'recall': array([1.]), 'precision': array([1.]), 'fscore': array([1.]), 'accuracy': 1.0}, 'up': {'recall': array([1.]), 'precision': array([1.]), 'fscore': array([1.]), 'accuracy': 1.0}, 'up_colours': {'recall': array([0.5, 0. ]), 'precision': array([1., 0.]), 'fscore': array([0.66666667, 0.        ]), 'accuracy': 0.5}}\n"
     ]
    }
   ],
   "source": [
    "from torchvision.models.detection.backbone_utils import resnet_fpn_backbone\r\n",
    "import torchvision\r\n",
    "import sys\r\n",
    "import os\r\n",
    "import confuse\r\n",
    "from pathlib import Path\r\n",
    "import torch\r\n",
    "import numpy as np\r\n",
    "import torch.nn as nn\r\n",
    "import torch.optim as optim\r\n",
    "from tqdm import tqdm\r\n",
    "import torch\r\n",
    "from torch.utils.tensorboard import SummaryWriter\r\n",
    "from sklearn.metrics import precision_recall_fscore_support\r\n",
    "from ignite.metrics import Precision\r\n",
    "from model2 import OverallModel\r\n",
    "from model2 import Classifier\r\n",
    "backbone = resnet_fpn_backbone(\r\n",
    "        'resnet50', pretrained=True, trainable_layers=0)\r\n",
    "cfg = confuse.Configuration('model_architecture', __name__, read=False)\r\n",
    "cfg.set_file(\r\n",
    "    \"C:\\\\Users\\\\netra\\\\GithubEncm369\\\\reid\\\\explainable-id-reid\\\\src\\\\model_util\\\\classifier_architecture.yml\")\r\n",
    "classifier_params = cfg.get()\r\n",
    "# The second argument is the output being used as a String,\r\n",
    "# \"1\", \"2\", \"3\", or \"pool\"\r\n",
    "obj = Classifier(classifier_params, \"3\")\r\n",
    "model = OverallModel(backbone, obj, \"3\")\r\n",
    "model = model.train()\r\n",
    "y_pred = {'age': torch.rand(2,4),\r\n",
    "          'backpack': torch.rand(2,1),\r\n",
    "          'bag': torch.rand(2,1),\r\n",
    "          'clothes': torch.rand(2,1),\r\n",
    "          'down': torch.rand(2,1),\r\n",
    "          'down_colours': torch.rand(2,9),\r\n",
    "          'gender': torch.rand(2,1),\r\n",
    "          'hair': torch.rand(2,1),\r\n",
    "          'handbag': torch.rand(2,1),\r\n",
    "          'hat': torch.rand(2,1),\r\n",
    "          'up': torch.rand(2,1),\r\n",
    "          'up_colours': torch.rand(2,8)}\r\n",
    "y_real = [{'age': torch.tensor([2]),\r\n",
    "          'backpack': torch.tensor([0]),\r\n",
    "          'bag': torch.tensor([1]),\r\n",
    "          'clothes': torch.tensor([1]),\r\n",
    "          'down': torch.tensor([0]),\r\n",
    "          'down_colours': torch.tensor([4]),\r\n",
    "          'gender': torch.tensor([0]),\r\n",
    "          'hair': torch.tensor([1]),\r\n",
    "          'handbag': torch.tensor([1]),\r\n",
    "          'hat': torch.tensor([0]),\r\n",
    "          'up': torch.tensor([1]),\r\n",
    "          'up_colours': torch.tensor([3])}, {'age': torch.tensor([2]),\r\n",
    "          'backpack': torch.tensor([0]),\r\n",
    "          'bag': torch.tensor([1]),\r\n",
    "          'clothes': torch.tensor([1]),\r\n",
    "          'down': torch.tensor([0]),\r\n",
    "          'down_colours': torch.tensor([4]),\r\n",
    "          'gender': torch.tensor([0]),\r\n",
    "          'hair': torch.tensor([1]),\r\n",
    "          'handbag': torch.tensor([1]),\r\n",
    "          'hat': torch.tensor([0]),\r\n",
    "          'up': torch.tensor([1]),\r\n",
    "          'up_colours': torch.tensor([3])}]\r\n",
    "print(y_pred)\r\n",
    "print(y_real)\r\n",
    "print(\"calculator\")\r\n",
    "print(model.metric_calculator(y_pred, y_real))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6bed49c7aa7523640f6fd13a92efef5eac85f440beffa398c5e11054be07d034"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('Python': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}